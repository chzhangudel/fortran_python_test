{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f1baff-c983-4fcd-87a6-c6a2ed3f59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as copy\n",
    "import matplotlib as mpl\n",
    "import netCDF4 as ncd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "cwd=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1d17d4-05eb-4cb3-9575-dcdc1652e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class learnKappa(nn.Module):\n",
    "    def __init__(self, In_nodes, Hid, Out_nodes):\n",
    "        \"\"\"\n",
    "        In_nodes: input vector (forcings)\n",
    "        H: hidden nodes\n",
    "        Out_nodes: outputs, here kappa\n",
    "        \n",
    "        nn.Linear is a module from pytorch nn....\n",
    "        \"\"\"\n",
    "        super(learnKappa, self).__init__()\n",
    "        self.linear1 = nn.Linear(In_nodes, Hid) \n",
    "        self.linear2 = nn.Linear(Hid, Hid) \n",
    "        #self.linear3 = nn.Linear(Hid, Hid) \n",
    "        self.linear4 = nn.Linear(Hid, Out_nodes)\n",
    "        #self.linear3 = nn.Linear(D_out, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "            \"\"\"\n",
    "            torch.sigmoid: sigmoid activation, many more options...\n",
    "            \"\"\"\n",
    "            x2=self.linear1(x)\n",
    "            h1 = torch.relu(x2)\n",
    "            #h1 = torch.sigmoid(x2)\n",
    "            #h_relu2= torch.relu(self.linear2(h_relu))\n",
    "            h2 = self.linear2(h1)\n",
    "            h3 = torch.relu(h2)\n",
    "            #h3 = torch.sigmoid(h2)\n",
    "            \n",
    "            #h4 = self.linear3(h3)\n",
    "            #h5 = torch.relu(h4)\n",
    "            \n",
    "            y_pred = self.linear4(h3)\n",
    "            #y_pred = torch.relu(h4)\n",
    "            #y_pred = torch.sigmoid(h4)\n",
    "            \n",
    "            return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e770fc03-d224-4852-a9b9-9b6b517ce806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learnKappa(\n",
      "  (linear1): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (linear4): Linear(in_features=64, out_features=16, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_nod, hid_nod, o_nod = 4, 64, 16\n",
    "model = learnKappa(in_nod, hid_nod, o_nod)\n",
    "model.load_state_dict(torch.load('test.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8cb0d5-012e-4a72-a92a-cb4bd75ff726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 528 µs, total: 528 µs\n",
      "Wall time: 448 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias', 'linear4.weight', 'linear4.bias'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6daa5dd1-a651-4a7c-81e9-24c36a0b9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dict=model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b0e9bd1-1dfe-49d9-8939-b023c38d831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias', 'linear4.weight', 'linear4.bias'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a27df47-6e25-4bd7-8ad2-d3d467595bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learnKappa(\n",
       "  (linear1): Linear(in_features=4, out_features=64, bias=True)\n",
       "  (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (linear4): Linear(in_features=64, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e07aeeed-f3d1-4e6e-b702-a41c522cfc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nno_of_paramters=len(mod_dict.keys())\\nno_of_paramters\\n\\n## create an array of strings to name the text files:\\nfile_name_str=[]\\nm=0\\nfor i in range(no_of_paramters):\\n    #file_name_str[i]='w'+str(i)\\n    if np.mod(i,2)==1:\\n        m=(int((i)/2))\\n        file_name_str.append('b'+str(m))\\n    else:\\n        m=(int((i)/2))\\n        file_name_str.append('w'+str(m))\\n    \\nfor j in range(no_of_paramters):\\n    np.savetxt(cwd+'/'+file_name_str[j]+'.txt',list(mod_dict.values())[j].detach().numpy())\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code converts the pytorch model 'test.pt' into 6 text files. uncomment to use it\n",
    "\n",
    "\"\"\"\n",
    "no_of_paramters=len(mod_dict.keys())\n",
    "no_of_paramters\n",
    "\n",
    "## create an array of strings to name the text files:\n",
    "file_name_str=[]\n",
    "m=0\n",
    "for i in range(no_of_paramters):\n",
    "    #file_name_str[i]='w'+str(i)\n",
    "    if np.mod(i,2)==1:\n",
    "        m=(int((i)/2))\n",
    "        file_name_str.append('b'+str(m))\n",
    "    else:\n",
    "        m=(int((i)/2))\n",
    "        file_name_str.append('w'+str(m))\n",
    "    \n",
    "for j in range(no_of_paramters):\n",
    "    np.savetxt(cwd+'/'+file_name_str[j]+'.txt',list(mod_dict.values())[j].detach().numpy())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd32363a-5ef6-465f-b283-46e234c13098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -368.21567    -639.21344    -838.50934    -877.9112     -777.6844\n",
      "  -762.0024    -1025.0791     -661.7102     -398.46683    -250.19112\n",
      "  -152.05328     -86.12348     -33.752163     -7.9902987    12.003361\n",
      "    59.25932  ]\n"
     ]
    }
   ],
   "source": [
    "# the array outt should match exactly with fortran output\n",
    "\n",
    "l=30.0; h=-50.0; t=0.3; hb=-100\n",
    "\n",
    "#l=(l-l_mean)/l_std; \n",
    "#h=(h-h_mean)/h_std; \n",
    "#t=(t-t_mean)/t_std; \n",
    "#hb=(hb-hb_mean)/hb_std; \n",
    "\n",
    "#l=l.astype('float32')\n",
    "input_array=np.array([l,h,t,hb],'float32')\n",
    "forc=Variable(torch.tensor(input_array))\n",
    "outt=model(forc)\n",
    "\n",
    "#k_mean=np.loadtxt('k_mean.txt')\n",
    "#k_std=np.loadtxt('k_std.txt')\n",
    "\n",
    "outt=outt.detach().numpy()\n",
    "print(outt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
